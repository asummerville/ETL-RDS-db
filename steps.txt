steps:

##SCRIPTING

#use kaggle datasets (look up some)

#write a script to ingest said data. kaggle api*** (include error handling)

#write another script to convert the file type of said data (include error handling)

#script to clean/transform the data. add/remove columns, etc. (include error handling)

#script that connects to a sql db and pushes the file to said db (include error handling)

#make sure to include a summary of what happend and where the file ended up

#write a "main" executable (CMD) shell script that takes one parameter (a url) and then just executes each of the above scripts
#maybe if the user runs main without a parameter it gives a useful message (instructions)

#README with instructions on how to use the container. tell them to run "main.py" with a url as the parameter

##DOCKER

#create a dockerfile in this folder that maps the folder and has a CMD to execute the main script


#User instructions

-look at https://www.kaggle.com/yamaerenay/spotify-dataset-19212020-160k-tracks?select=data_o.csv for the dataset
-input parameters into the main.sh script (file name, kaggle_username, kaggle_key, possibly sql stuff...)
-script will fetch the requested file, tranform it, and push it to a sql database