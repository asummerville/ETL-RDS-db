steps:

##SCRIPTING

#use kaggle datasets (look up some)

#write a script to ingest said data. kaggle api*** (include error handling)

#write another script to convert the file type of said data (include error handling)

#script to clean/transform the data. add/remove columns, etc. (include error handling)

#script that connects to a sql db and pushes the file to said db (include error handling)

#make sure to include a summary of what happend and where the file ended up

#write a "main" executable (CMD) shell script that takes one parameter (a url) and then just executes each of the above scripts
#maybe if the user runs main without a parameter it gives a useful message (instructions)

#README with instructions on how to use the container. tell them to run "main.py" with a url as the parameter

##DOCKER

#create a dockerfile in this folder that maps the folder and has a CMD to execute the main script


#TO DO:

-choose a dataset to work with (so the ingest script will be complete)
-start the convert script (figure out how to access the data variable in the other module)
-maybe ask neal about pushing to a RDS database and how that'll work...